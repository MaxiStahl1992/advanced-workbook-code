{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with Fictitious Data\n",
    "Scenario: Imagine we are developing a machine learning model to evaluate the effectiveness of an AI-driven tutoring system on student performance. Our initial dataset includes:\n",
    "\n",
    "Independent variable: Use of the AI-driven tutoring system (Yes/No)\n",
    "Dependent variable: Improvement in test scores\n",
    "Potential confounder: Prior academic performance (measured as previous test scores)\n",
    "Hypothetical Data:\n",
    "\n",
    "Group 1 (AI tutoring): 100 students; average previous test score: 75%; average improvement: 10%\n",
    "Group 2 (No AI tutoring): 100 students; average previous test score: 60%; average improvement: 5%\n",
    "Observation: It appears that using the AI tutoring system leads to better improvement. However, the prior academic performance, which is higher in the AI tutoring group, could be a confounder influencing both the usage of the tutoring system and the test score improvement.\n",
    "\n",
    "Addressing the Confounder with Propensity Score Matching:\n",
    "\n",
    "Calculate Propensity Scores: For each student, calculate the probability of using the AI tutoring system based on their previous test scores.\n",
    "Match Students: Pair students from both groups who have similar propensity scores.\n",
    "Re-evaluate the Outcome: Compare the average improvement in test scores between the matched students from both groups.\n",
    "Expected Result After Adjustment:\n",
    "\n",
    "After matching, suppose both groups have a more comparable average previous test score (~70%). If we still observe a higher average improvement in the AI tutoring group (e.g., 8% vs. 5%), we can be more confident that the observed effect is due to the tutoring system, rather than the confounding effect of prior academic performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy: 0.79\n",
      "Adjusted Model Accuracy: 0.88\n",
      "Base Model AUC: 0.7498493068113321\n",
      "Adjusted Model AUC: 0.945750452079566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# More pronounced effect of the confounder\n",
    "np.random.seed(73)\n",
    "data_size = 200\n",
    "\n",
    "prior_scores = np.concatenate([np.random.normal(75, 15, data_size//2), np.random.normal(60, 15, data_size//2)])\n",
    "treatment = np.array([1] * (data_size//2) + [0] * (data_size//2))\n",
    "# Increased influence of prior scores and added non-linear component\n",
    "improvement = (prior_scores * 0.5 + np.random.normal(0, 5, data_size) + treatment * 5).astype(int)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Prior Academic Performance': prior_scores,\n",
    "    'AI Tutoring': treatment,\n",
    "    'Improvement': improvement\n",
    "})\n",
    "\n",
    "# Defining binary outcome more dynamically\n",
    "median_improvement = np.percentile(data['Improvement'], 80)  # Adjust percentile to control difficulty\n",
    "y = (data['Improvement'] > median_improvement).astype(int)\n",
    "\n",
    "# Split data\n",
    "X_base = data[['AI Tutoring']]\n",
    "X_adjusted = data[['AI Tutoring', 'Prior Academic Performance']]\n",
    "X_base_train, X_base_test, y_train, y_test = train_test_split(X_base, y, test_size=0.5, random_state=42)\n",
    "X_adj_train, X_adj_test, _, _ = train_test_split(X_adjusted, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Models\n",
    "model_base = LogisticRegression()\n",
    "model_adjusted = LogisticRegression()\n",
    "model_base.fit(X_base_train, y_train)\n",
    "model_adjusted.fit(X_adj_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "base_preds = model_base.predict(X_base_test)\n",
    "adjusted_preds = model_adjusted.predict(X_adj_test)\n",
    "print(\"Base Model Accuracy:\", accuracy_score(y_test, base_preds))\n",
    "print(\"Adjusted Model Accuracy:\", accuracy_score(y_test, adjusted_preds))\n",
    "print(\"Base Model AUC:\", roc_auc_score(y_test, model_base.predict_proba(X_base_test)[:, 1]))\n",
    "print(\"Adjusted Model AUC:\", roc_auc_score(y_test, model_adjusted.predict_proba(X_adj_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Results\n",
    "Base Model Accuracy (0.79): This model, which does not consider prior academic performance, provides decent performance. However, it does not capture all the variability in the outcome because it misses a critical piece of information—prior academic scores—which influences both the likelihood of receiving treatment (AI tutoring) and the improvement.\n",
    "Adjusted Model Accuracy (0.88): With the inclusion of the confounder (prior academic performance), the model's accuracy improves significantly. This suggests that prior academic performance is a substantial factor in predicting the outcome and that its inclusion helps the model more accurately segment the students who are likely to show improvement.\n",
    "Base Model AUC (0.75): The Area Under the Curve (AUC) for the ROC curve in the base model indicates moderate discriminative ability. This suggests that while the model can distinguish between the two classes (improvement vs. no improvement), there is room for improvement.\n",
    "Adjusted Model AUC (0.95): A very high AUC in the adjusted model indicates excellent discrimination between positive and negative classes. This shows that the model with the confounder can effectively identify the nuances between students who improve and those who do not, based on their prior scores and whether or not they received AI tutoring.\n",
    "Conclusion\n",
    "These results strongly support the argument for including relevant confounders in predictive modeling, especially when those confounders have a significant impact on both the treatment and the outcome. By adjusting for these confounders, you can achieve more accurate and reliable predictions, which are crucial for causal inference and for making informed decisions based on model outcomes.\n",
    "\n",
    "Next Steps\n",
    "Given these results, your paper could discuss:\n",
    "\n",
    "The importance of identifying and adjusting for confounders in studies involving AI and machine learning.\n",
    "The statistical impact of including these confounders in terms of model performance metrics such as accuracy and AUC.\n",
    "Potential implications for deploying AI systems in educational settings or other domains where such confounders might exist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
